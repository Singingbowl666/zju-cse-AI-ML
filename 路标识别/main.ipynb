{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的机器视觉 - 路标识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.实验介绍\n",
    "## 1.2实验背景\n",
    "无人驾驶日益成熟，路标检测是其中一个基础任务，需要达到非常高的准确率来为后续的决策做支撑。\n",
    "\n",
    "## 1.2 实验要求\n",
    "a）建立深度神经网络模型，并尽可能将其调到最佳状态。   \n",
    "b）绘制深度神经网络模型图、绘制并分析学习曲线。  \n",
    "c）用准确率等指标对模型进行评估。\n",
    "\n",
    "## 1.3 实验环境\n",
    "可以使用基于 Python 的 OpenCV 库进行图像相关处理，使用 Numpy 库进行相关数值运算，使用 pytorch 等框架建立深度学习模型等。\n",
    "\n",
    "## 1.4 注意事项\n",
    "+ Python 与 Python Package 的使用方式，可在右侧 `API文档` 中查阅。\n",
    "+ 当右上角的『Python 3』长时间指示为运行中的时候，造成代码无法执行时，可以重新启动 Kernel 解决（左上角『Kernel』-『Restart Kernel』）\n",
    "\n",
    "\n",
    "## 1.5 参考资料\n",
    "OpenCV：https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html  \n",
    "Numpy：https://www.numpy.org/  \n",
    "PyTorch：https://pytorch.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.实验内容\n",
    "## 2.1 介绍数据集\n",
    "GTSRB 是一个多类图像识别数据集。\n",
    "\n",
    "+ 43类交通标注\n",
    "+ 超过50000张图片\n",
    "\n",
    "\n",
    "+ 物品都是放在白板上在日光/室内光源下拍摄的，压缩后的尺寸为 512 * 384\n",
    "\n",
    "导入数据集成功后路径：  \n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2划分验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1划分之前的准备\n",
    "因为挂载过来的数据比较凌乱，我们只需要到训练集数据，这里我们新建数据集路径./data 将原文件的train数据拷贝过来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 创建目标目录\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "    print(\"目录 'data' 已创建。\")\n",
    "else:\n",
    "    print(\"目录 'data' 已存在。\")\n",
    "\n",
    "# 复制文件夹内容\n",
    "src_path = \"./datasets/meowmeowmeowmeowmeow-gtsrb-german-traffic-sign-momodel/train\"\n",
    "dst_path = \"./data/train_images\"\n",
    "\n",
    "if os.path.exists(src_path):\n",
    "    if not os.path.exists(dst_path):\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "        print(f\"已成功将 {src_path} 的内容复制到 {dst_path}。\")\n",
    "    else:\n",
    "        print(f\"目标目录 {dst_path} 已存在，跳过复制。\")\n",
    "else:\n",
    "    print(f\"源路径 {src_path} 不存在，请检查路径。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2划分数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个图片名称前六位表示类别，中间6位数表示组数，一组有30张图片，这里将前三组划分为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def initialize_data(folder):\n",
    "    # make validation_data by using images 00000*, 00001* and 00002* in each class\n",
    "    train_folder = folder + '/train_images'\n",
    "    val_folder = folder + '/val_images'\n",
    "    if not os.path.isdir(val_folder):\n",
    "        print(val_folder + ' not found, making a validation set')\n",
    "        os.mkdir(val_folder)\n",
    "        for dirs in os.listdir(train_folder):\n",
    "            os.mkdir(val_folder + '/' + dirs)\n",
    "            for f in os.listdir(train_folder + '/' + dirs):\n",
    "                if f[6:11]==('00000') or f[6:11]==('00001') or f[6:11]==('00002'):\n",
    "                    # move file to validation folder\n",
    "                    os.rename(train_folder + '/' + dirs + '/' + f, val_folder + '/' + dirs + '/' + f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "initialize_data(data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在随机展示其中的 6 张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关包\n",
    "import glob, os\n",
    "\n",
    "# 数据集路径\n",
    "\n",
    "\n",
    "# 获取数据名称列表\n",
    "img_list = glob.glob(os.path.join(data_path, '*/*/*.png'))\n",
    "\n",
    "# 打印数据集总量\n",
    "print(\"数据集总数量:\", len(img_list))\n",
    "\n",
    "import random,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 从数据名称列表 img_list 中随机选取 6 个。\n",
    "for i, img_path in enumerate(random.sample(img_list, 6)):\n",
    "\n",
    "    # 读取图片\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # 将图片从 BGR 模式转为 RGB 模式\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 将窗口设置为 2 行 3 列 6个子图\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "\n",
    "    # 展示图片\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # 不显示坐标尺寸\n",
    "    plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data augmentation for training and test time\n",
    "# Resize all images to 32 * 32 and normalize them to mean = 0 and standard-deviation = 1 based on statistics collected from the training set\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "# Resize, normalize and jitter image brightness\n",
    "data_jitter_brightness = transforms.Compose([\n",
    "\ttransforms.Resize((32, 32)),\n",
    "#     transforms.ColorJitter(brightness=-5),\n",
    "    transforms.ColorJitter(brightness=5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "应用数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(data_path,batch_size,use_gpu):\n",
    "    import torch\n",
    "    from torchvision import datasets, transforms\n",
    "    \"\"\"\n",
    "    数据处理\n",
    "    :param data_path: 数据集路径\n",
    "    :return:  train_loader,val_loader:处理后的训练集,验证集loader\n",
    "    \"\"\"\n",
    "    #这里是把字典序转为按数字大小排列的序号 比如10这个文件夹的图片，原本通过datasets.ImageFolder获取到的label是2（按字典序排列 0，1，10，11，12，13...），现在转换为10\n",
    "    def char_order2int_order(charoder):\n",
    "        a = []\n",
    "        for i in range(43):\n",
    "            a.append(str(i))\n",
    "        a.sort()\n",
    "        kv={}\n",
    "        for i in range (43):\n",
    "            kv[i]=int(a[i])\n",
    "        return kv[charoder]\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "       torch.utils.data.ConcatDataset([\n",
    "       datasets.ImageFolder(data_path + '/train_images',transform=data_transforms,target_transform=char_order2int_order),\n",
    "       datasets.ImageFolder(data_path + '/train_images',transform=data_jitter_brightness,target_transform=char_order2int_order),\n",
    "\n",
    "                                      ]),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(data_path + '/val_images',transform=data_transforms,target_transform=char_order2int_order),\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    return train_loader,val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对单张图片应用变换器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "transforms = transforms.Compose([\n",
    "transforms.Resize((32, 32)),\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "from PIL import Image\n",
    "img=Image.open(\"./data/train_images/0/00000_00003_00000.png\")\n",
    "img=transforms(img)\n",
    "plt.imshow(img.permute(1,2,0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4网络架构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nclasses = 43  # GTSRB as 43 classes\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(250 * 2 * 2, 350)\n",
    "        self.fc2 = nn.Linear(350, nclasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = x.view(-1, 250 * 2 * 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1训练函数和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if use_gpu:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target,reduction=\"sum\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim=1)[1]\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "    print('\\nTraining set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        training_loss / len(train_loader.dataset), correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    return training_loss / len(train_loader.dataset), 100. * correct / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def validation():\n",
    "    from torch.autograd import Variable\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx,(data, target) in enumerate(tqdm(val_loader)):\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            if use_gpu:\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(data)\n",
    "            validation_loss += F.nll_loss(output, target, reduction=\"sum\").data.item()  # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "#     scheduler.step(np.around(validation_loss, 2))\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss/len(val_loader.dataset), correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return validation_loss/len(val_loader.dataset), 100. * correct / len(val_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2训练超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#参数设置\n",
    "class args:\n",
    "    data = \"./data\"\n",
    "    batch_size = 64\n",
    "    epochs = 20\n",
    "    lr = 0.0001\n",
    "    seed = 1\n",
    "    log_interval = 10\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    use_gpu = True\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "\tuse_gpu = False\n",
    "\tprint(\"Using CPU\")\n",
    "\n",
    "train_loader,val_loader=processing_data(args.data,args.batch_size,use_gpu)\n",
    "model = Net()\n",
    "\n",
    "#优化器和学习率调整\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad,model.parameters()),lr=args.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=5,factor=0.5,verbose=True)\n",
    "\n",
    "\n",
    "res={\"loss\":[],\"val_loss\":[],\"accuracy\":[],\"val_accuracy\":[]}\n",
    "#开始训练\n",
    "start = time.time()\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    loss,acc=train(epoch)\n",
    "    res[\"loss\"].append(loss.cpu())\n",
    "    res[\"accuracy\"].append(acc.cpu())\n",
    "    loss,acc=validation()\n",
    "    res[\"val_loss\"].append(loss)\n",
    "    res[\"val_accuracy\"].append(acc)\n",
    "    model_file = 'results/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file,_use_new_zipfile_serialization=False)\n",
    "    print('\\nSaved model to ' + model_file )\n",
    "\n",
    "print(\"模型训练总时长：\",time.time()-start)\n",
    "import pickle\n",
    "with open(\"./results/res\",\"wb\") as f:\n",
    "    pickle.dump(res,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3模型训练过程图形化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_history(res):\n",
    "    \"\"\"\n",
    "    绘制模型的训练结果\n",
    "    :param res: 模型的训练结果\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 绘制模型训练过程的损失和平均损失\n",
    "    # 绘制模型训练过程的损失值曲线，标签是 loss\n",
    "    plt.plot(res['loss'], label='loss')\n",
    "\n",
    "    # 绘制模型训练过程中的平均损失曲线，标签是 val_loss\n",
    "    plt.plot(res['val_loss'], label='val_loss')\n",
    "\n",
    "    # 绘制图例,展示出每个数据对应的图像名称和图例的放置位置\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # 展示图片\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制模型训练过程中的的准确率和平均准确率\n",
    "    # 绘制模型训练过程中的准确率曲线，标签是 acc\n",
    "    plt.plot(res['accuracy'], label='accuracy')\n",
    "\n",
    "    # 绘制模型训练过程中的平均准确率曲线，标签是 val_acc\n",
    "    plt.plot(res['val_accuracy'], label='val_accuracy')\n",
    "\n",
    "    # 绘制图例,展示出每个数据对应的图像名称，图例的放置位置为默认值。\n",
    "    plt.legend()\n",
    "\n",
    "    # 展示图片\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制模型训练过程曲线\n",
    "#加载gpu训练的结果\n",
    "import pickle\n",
    "with open(\"./results/res\", \"rb\") as f:\n",
    "    res=pickle.load(f)\n",
    "plot_training_history(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6加载模型和模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "_,val_loader=processing_data(args.data,args.batch_size,use_gpu=False)\n",
    "model_file = './results/model_1.pth'\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load(model_file, map_location=torch.device('cpu')))\n",
    "\n",
    "# model.eval()\n",
    "validation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7作业\n",
    "通过对以上步骤流程的了解，相信大家对深度学习有了深刻的认识，但是模型比较简单，准确率也不高，大家可以试着写自己的深度学习模型，并将其调到最佳状态。在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1 训练深度学习模型\n",
    "\n",
    "深度学习模型训练流程, 包含数据处理、创建模型、训练模型、模型保存、评价模型等。  \n",
    "如果对训练出来的模型不满意, 你可以通过调整模型的参数等方法重新训练模型, 直至训练出你满意的模型。  \n",
    "如果你对自己训练出来的模型非常满意, 则可以提交作业报告!  \n",
    "\n",
    "注意：\n",
    "\n",
    "1. 你可以在我们准好的接口中实现深度学习模型（若使用可以修改函数接口），也可以自己实现深度学习模型。\n",
    "2. 写好代码后可以在 Py 文件中使用 GPU 进行模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(data_path):\n",
    "    \"\"\"\n",
    "    数据处理\n",
    "    :param data_path: 数据集路径\n",
    "    :return: train, test:处理后的训练集数据、测试集数据\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(data_path, 'train_images'), transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=os.path.join(data_path, 'val_images'), transform=transform)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def model(train_data, test_data, save_model_path):\n",
    "    \"\"\"\n",
    "    创建、训练和保存深度学习模型\n",
    "    :param train_data: 训练集数据\n",
    "    :param test_data: 测试集数据\n",
    "    :param save_model_path: 保存模型的路径和名称\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ResNet18(num_classes=len(train_loader.dataset.classes)).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_mode(test_data, save_model_path):\n",
    "    \"\"\"\n",
    "    加载模型和评估模型\n",
    "    可以实现，比如: 模型训练过程中的学习曲线，测试集数据的loss值、准确率及混淆矩阵等评价指标！\n",
    "    主要步骤:\n",
    "        1.加载模型(请填写你训练好的最佳模型),\n",
    "        2.对自己训练的模型进行评估\n",
    "\n",
    "    :param test_data: 测试集数据\n",
    "    :param save_model_path: 加载模型的路径和名称,请填写你认为最好的模型\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ----------------------- 实现模型加载和评估等部分的代码 -----------------------\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ResNet18(num_classes=len(test_loader.dataset.classes))\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_loader.dataset.classes, yticklabels=test_loader.dataset.classes)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    # ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    深度学习模型训练流程,包含数据处理、创建模型、训练模型、模型保存、评价模型等。\n",
    "    如果对训练出来的模型不满意,你可以通过调整模型的参数等方法重新训练模型,直至训练出你满意的模型。\n",
    "    如果你对自己训练出来的模型非常满意,则可以提交作业!\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_path = \"./data\" # 数据集路径\n",
    "    model_file = './results/model_1.pth'\n",
    "\n",
    "    # 获取数据\n",
    "    train_data, test_data = processing_data(data_path)\n",
    "\n",
    "    # 创建、训练和保存模型\n",
    "    model(train_data, test_data, save_model_path)\n",
    "\n",
    "    # 评估模型\n",
    "    evaluate_mode(test_data, save_model_path)\n",
    "\n",
    "    #pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.7.2 模型预测\n",
    "\n",
    "\n",
    "注意：\n",
    "1. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "2. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "3. 请加载你认为训练最佳的模型，即请按要求填写模型路径。\n",
    "4. `predict()`函数的输入和输出请不要改动。\n",
    "5. 作业测试时记得填写你的模型路径及名称, 如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请将模型保存在 **results** 文件夹下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  ===========================================  \n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "# -------------------------- 请加载您最满意的模型 ---------------------------\n",
    "# 加载模型(请加载你认为的最佳模型)\n",
    "# 加载模型,加载请注意 model_path 是相对路径, 与当前文件同级。\n",
    "# 如果你的模型是在 results 文件夹下的 model_1.pth 模型，则 model_path = 'results/model_1.pth'\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(BasicBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model_path = './results/model.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18(num_classes=43)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "def predict(img):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    主要步骤:\n",
    "        1.图片处理\n",
    "        2.用加载的模型预测图片的类别\n",
    "    :param img: PIL.Image 对象\n",
    "    :return: int, 模型识别图片的类别\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    # 获取图片的类别\n",
    "    # 把图片转换成为tensor\n",
    "    if isinstance(img, str):\n",
    "        img = Image.open(img).convert(\"RGB\")\n",
    "    if not isinstance(img, Image.Image):\n",
    "        raise TypeError(f\"img should be PIL Image. Got {type(img)}\")\n",
    "\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        # transforms.RandomRotation(15),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    print(\"predicted:\",predicted)\n",
    "    index_list = [0,1,10,11,12,13,14,15,16,17,18,19,2,20,21,22,23,24,25,26,27,28,29,3,30,31,32,33,34,35,36,37,38,39,4,40,41,42,5,6,7,8,9]\n",
    "        \n",
    "    predict_index = predicted.item()\n",
    "    y_predict = index_list[predict_index]\n",
    "    # 获取输入图片的类别\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # 返回图片的类别\n",
    "    return y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 输入图片路径和名称\n",
    "img_path = 'test_with_label_3.png'\n",
    "\n",
    "# 打印该张图片的类别\n",
    "print(predict(img_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
