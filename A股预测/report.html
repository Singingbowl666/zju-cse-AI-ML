<!DOCTYPE html><html><head>
      <title>report</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\61583\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.18\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h2 id="center-a股预测实验报告-center"><center> A股预测实验报告 </center> </h2>
<h3 id="一-实验目的">一、实验目的 </h3>
<ul>
<li>学习了解深度学习模型的基本框架，包括数据集的划分，模型的搭建，训练，评估等基本步骤。</li>
<li>了解并掌握针对时序问题的深度学习模型（如LSTM等）</li>
</ul>
<h3 id="二-实验内容">二、实验内容 </h3>
<ul>
<li>给定某股票前 14 个交易日的收盘价，预测下一个交易日的收盘价。最终效果的评价指标为平均绝对百分比误差和平均绝对误差。</li>
<li>自己构建一个深度学习模型，使用提供的训练数据（包含五十多支股票前 14 个交易日的收盘价和下一个交易日的收盘价）进行训练，然后利用训练好的模型进行预测。</li>
</ul>
<h3 id="三-实现过程与具体代码">三、实现过程与具体代码 </h3>
<p><strong>数据的划分与预处理：</strong><br>
实验中给定的数据集包含五十多支股票的历史数据，每支股票包含前 14 个交易日的收盘价和下一个交易日的收盘价，我们首先读取该数据集中的数据，然后将每一支股票的前14个数据作为自变量，第十五个数据作为因变量并将其转换为numpy数组方便后续计算。<br>
代码如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 获取文件名</span>
file_name <span class="token operator">=</span> <span class="token string">'train_data.npy'</span>

<span class="token comment"># 读取数组</span>
data <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>file_name<span class="token punctuation">)</span>

<span class="token comment"># 生成题目所需的训练集合</span>
<span class="token keyword keyword-def">def</span> <span class="token function">generate_data</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 记录 data 的长度</span>
    n <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token comment"># 目标是生成可直接用于训练和测试的 x 和 y</span>
    x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token comment"># 建立 (14 -&gt; 1) 的 x 和 y</span>
    <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">15</span><span class="token punctuation">:</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 转换为 numpy 数组</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>

    <span class="token keyword keyword-return">return</span> x<span class="token punctuation">,</span>y

x<span class="token punctuation">,</span>y <span class="token operator">=</span> generate_data<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><p>接着，我们将数据集划分为训练集、校验集和测试集，其中训练集占70%，测试集占20%，校验集占10%，校验集和测试集用于测试和评估训练得到的模型的效果。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 生成 train valid test 集合，以供训练所需</span>
<span class="token keyword keyword-def">def</span> <span class="token function">generate_training_data</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 样本总数</span>
    num_samples <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token comment"># 测试集大小</span>
    num_test <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>num_samples <span class="token operator">*</span> <span class="token number">0.2</span><span class="token punctuation">)</span>
    <span class="token comment"># 训练集大小</span>
    num_train <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>num_samples <span class="token operator">*</span> <span class="token number">0.7</span><span class="token punctuation">)</span>
    <span class="token comment"># 校验集大小</span>
    num_val <span class="token operator">=</span> num_samples <span class="token operator">-</span> num_test <span class="token operator">-</span> num_train

    <span class="token comment"># 训练集拥有从 0 起长度为 num_train 的样本</span>
    x_train<span class="token punctuation">,</span> y_train <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span>num_train<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span><span class="token punctuation">:</span>num_train<span class="token punctuation">]</span>
    <span class="token comment"># 校验集拥有从 num_train 起长度为 num_val 的样本</span>
    x_val<span class="token punctuation">,</span> y_val <span class="token operator">=</span> <span class="token punctuation">(</span>
        x<span class="token punctuation">[</span>num_train<span class="token punctuation">:</span> num_train <span class="token operator">+</span> num_val<span class="token punctuation">]</span><span class="token punctuation">,</span>
        y<span class="token punctuation">[</span>num_train<span class="token punctuation">:</span> num_train <span class="token operator">+</span> num_val<span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># 测试集拥有尾部 num_test 个样本</span>
    x_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token operator">-</span>num_test<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span><span class="token operator">-</span>num_test<span class="token punctuation">:</span><span class="token punctuation">]</span>

    <span class="token comment"># 返回这些集合</span>
    <span class="token keyword keyword-return">return</span> x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test

x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> generate_training_data<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre><p>然后，由于我们采用pytorch框架，我们需要将数据集转换为pytorch的数据集，以便于后续训练，即将自变量和因变量都转化为tensor形式并将因变量转化为列向量。</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 获取数据中的 x, y</span>
x<span class="token punctuation">,</span>y <span class="token operator">=</span> generate_data<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment"># 将 x,y 转换乘 tensor ， Pytorch 模型默认的类型是 float32</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># 将 y 转化形状</span>
y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre><p>接着，由于不同股票的价格差异过大，我们需要对数据进行归一化处理，防止数值大的数据主导模型计算，导致结果失真</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token keyword keyword-from">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword keyword-import">import</span> MinMaxScaler

<span class="token comment"># 这个 [0, 300] 是手动的预设值，可以自己更改</span>
scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 对 x, y 进行 minmaxscale</span>
x_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">)</span>
y_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span>

x_scaled <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x_scaled<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y_scaled <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y_scaled<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
<span class="token comment"># 处理出训练集，校验集和测试集</span>
x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> generate_training_data<span class="token punctuation">(</span>x_scaled<span class="token punctuation">,</span> y_scaled<span class="token punctuation">)</span>
</code></pre><p>然后，我们自己创建一个dataset并采用pytorch的dataloader来加载数据集，其中dataloader可以自动将数据集分批次加载，每次加载batch_size个数据，保证训练精度的同时减少了显存压力。同时dataloder会将训练数据打乱，防止模型过拟合</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 建立一个自定 Dataset</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">MyDataset</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y

    <span class="token keyword keyword-def">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> self<span class="token punctuation">.</span>x<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>item<span class="token punctuation">]</span>

    <span class="token keyword keyword-def">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span>
<span class="token comment"># 建立训练数据集、校验数据集和测试数据集</span>
train_data <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
valid_data <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>x_val<span class="token punctuation">,</span>y_val<span class="token punctuation">)</span>
test_data <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>
<span class="token comment"># 规定批次的大小</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>

<span class="token comment"># 创建对应的 DataLoader</span>
train_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 校验集和测试集的 shuffle 是没有必要的，因为每次都会全部跑一遍</span>
valid_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>valid_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
test_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre><p><strong>模型的搭建：</strong><br>
在进行完数据的加载、划分与预处理后，我们需要构架一个深度学习网络，用于训练和预测。在本次实验中，我们采用了LSTM模型，LSTM模型是一种适用于时序问题的深度学习模型，能够很好地捕捉时序数据的特征。LSTM模型的基本原理如下：</p>
<ul>
<li>一个 LSTM 单元核心结构包括 3 个门 + 1 个细胞状态（记忆单元）</li>
<li>遗忘门用于决定从上一个时间步的记忆中丢弃多少信息；输入门决定当前新信息中，哪些要写入记忆单元（候选记忆）；记忆单元用于将旧的记忆和新的候选记忆结合，作为新的记忆；输出门用于决定输出的记忆单元的哪些部分(下图中的h_t代表隐藏层)</li>
</ul>
<pre data-role="codeBlock" data-info="cpp" class="language-cpp cpp"><code>                ┌─────────────┐
      h_<span class="token punctuation">{</span>t<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">}</span> ─▶│             │
     x_t  ─────▶│   LSTM 单元 │──▶ h_t
                │             │
      C_<span class="token punctuation">{</span>t<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">}</span> ─▶│             │──▶ C_t
                └─────────────┘
</code></pre><p>由于LSTM网络能模仿记忆神经元的工作特性，即可以记住很久以前的信息，能够处理长依赖问题，以及它能有效控制信息流动，从而避免梯度消失和梯度爆炸问题，因此在时序问题中应用广泛。借助pytorch框架，我们可以很方便地搭建一个LSTM模型，代码如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 定义 LSTM 模型（在 train() 内部）</span>
<span class="token keyword keyword-class">class</span> <span class="token class-name">LSTMPredictor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTMPredictor<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers

        <span class="token comment"># LSTM 层</span>
        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 全连接层</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

    <span class="token keyword keyword-def">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        c0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span>h0<span class="token punctuation">,</span> c0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> out
</code></pre><p><strong>模型的训练：</strong><br>
在搭建好模型后，我们需要对模型进行训练，训练的目的是通过不断迭代，使模型的预测结果与真实结果之间的误差不断减小，从而提高模型的预测精度。在每次迭代过程中，我们先初始化梯度，然后将自变量输入模型得到输出，再计算模型的输出和真实的输出之间的损失，接着计算每个参数相对于损失的梯度，最后将参数沿着梯度的方向以学习率为步长进行更新。在训练过程中，我们需要定义损失函数和优化器，损失函数用于衡量模型的预测结果与真实结果之间的差距，优化器用于调整模型的参数，使损失函数最小化。在本次实验中，我们采用了均方误差损失函数和Adam优化器。<br>
代码如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code><span class="token comment"># 定义超参数</span>
input_size <span class="token operator">=</span> <span class="token number">1</span>       <span class="token comment"># 输入特征维度（假设只输入股票价格）</span>
hidden_size <span class="token operator">=</span> <span class="token number">64</span>     <span class="token comment"># LSTM 隐藏层大小</span>
num_layers <span class="token operator">=</span> <span class="token number">2</span>       <span class="token comment"># LSTM 层数</span>
output_size <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment"># 预测输出</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>
num_epochs <span class="token operator">=</span> <span class="token number">80</span>      <span class="token comment"># 训练轮数</span>

<span class="token comment"># 创建 LSTM 模型</span>
model <span class="token operator">=</span> LSTMPredictor<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 均方误差</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>

<span class="token comment"># 训练循环</span>
<span class="token keyword keyword-for">for</span> epoch <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>

    <span class="token keyword keyword-for">for</span> features<span class="token punctuation">,</span> labels <span class="token keyword keyword-in">in</span> train_iter<span class="token punctuation">:</span>  <span class="token comment"># 遍历训练数据</span>

        features<span class="token punctuation">,</span> labels <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        <span class="token comment"># **修改：确保 features 形状为 (batch_size, sequence_length, input_size)**</span>
        features <span class="token operator">=</span> features<span class="token punctuation">.</span>view<span class="token punctuation">(</span>features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>

        <span class="token comment"># **修改：确保 labels 形状与 outputs 匹配**</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 清空梯度</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>features<span class="token punctuation">)</span>  <span class="token comment"># 前向传播</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>  <span class="token comment"># 计算损失</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 反向传播</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 更新参数</span>

        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>running_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token comment"># print("Loss: {:.6f}".format(running_loss / len(train_iter)))</span>
</code></pre><p><strong>模型的评估与测试：</strong><br>
模型训练好之后，我们需要对模型进行评估和测试，首先我们将模型设置为评估模式，然后对校验集和测试集进行预测，计算模型的损失，最后输出模型的评估结果。对于评估和测试的损失，我们也采用了均方误差损失函数。<br>
代码如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 设置模型为评估模式</span>
total_loss <span class="token operator">=</span> <span class="token number">0.0</span>
total_samples <span class="token operator">=</span> <span class="token number">0</span>

<span class="token keyword keyword-with">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 在评估时不计算梯度，加速计算并节省显存</span>
    <span class="token keyword keyword-for">for</span> x_batch<span class="token punctuation">,</span> y_batch <span class="token keyword keyword-in">in</span> valid_iter<span class="token punctuation">:</span>
        x_batch<span class="token punctuation">,</span> y_batch <span class="token operator">=</span> x_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 确保数据在同一设备上</span>
        <span class="token comment"># **修改：确保 x_batch 形状**</span>
        x_batch <span class="token operator">=</span> x_batch<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x_batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>
        y_batch <span class="token operator">=</span> y_batch<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_batch<span class="token punctuation">)</span>  <span class="token comment"># 进行预测</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y_batch<span class="token punctuation">)</span>  <span class="token comment"># 计算损失</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> x_batch<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 累加损失</span>
        total_samples <span class="token operator">+=</span> x_batch<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 统计样本数量</span>

avg_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> total_samples
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"valid Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>avg_loss<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>  <span class="token comment"># 只保留6位小数</span>

total_loss <span class="token operator">=</span> <span class="token number">0.0</span>
total_samples <span class="token operator">=</span> <span class="token number">0</span>

<span class="token keyword keyword-with">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 在评估时不计算梯度，加速计算并节省显存</span>
    <span class="token keyword keyword-for">for</span> x_batch<span class="token punctuation">,</span> y_batch <span class="token keyword keyword-in">in</span> test_iter<span class="token punctuation">:</span>
        x_batch<span class="token punctuation">,</span> y_batch <span class="token operator">=</span> x_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y_batch<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 确保数据在同一设备上</span>
        <span class="token comment"># **修改：确保 x_batch 形状**</span>
        x_batch <span class="token operator">=</span> x_batch<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x_batch<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>
        y_batch <span class="token operator">=</span> y_batch<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_batch<span class="token punctuation">)</span>  <span class="token comment"># 进行预测</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y_batch<span class="token punctuation">)</span>  <span class="token comment"># 计算损失</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> x_batch<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 累加损失</span>
        total_samples <span class="token operator">+=</span> x_batch<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 统计样本数量</span>

avg_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> total_samples
<span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"test Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>avg_loss<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>  <span class="token comment"># 只保留6位小数</span>
</code></pre><p><strong>模型的预测：</strong><br>
模型训练好之后，我们保存模型的参数，并在预测时创建同样的LSTM模型，然后加载训练好的参数，对新的数据进行预测（注意由于我们训练时对模型的输入输出进行了归一化操作，在预测时也应对输入的数据进行归一化以符合模型特征，再将模型的输出恢复到归一化前的尺度）。<br>
代码如下：</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>model_path <span class="token operator">=</span> <span class="token string">'results/mymodel.pt'</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword keyword-def">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>test_x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># test 的数目</span>
    n_test <span class="token operator">=</span> test_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    test_y <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token comment"># --------------------------- 此处下方加入读入模型和预测相关代码 -------------------------------</span>
    <span class="token comment"># 此处为 Notebook 模型示范，你可以根据自己数据处理方式进行改动</span>
    scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_x <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>test_x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span>
    
    test_x <span class="token operator">=</span> test_x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>n_test<span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    test_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>test_x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

    test_y <span class="token operator">=</span> model<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>

    <span class="token comment"># 如果使用 MinMaxScaler 进行数据处理，预测后应使用下一句将预测值放缩到原范围内</span>
    test_y <span class="token operator">=</span> scaler<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-if">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>test_y<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>
        test_y <span class="token operator">=</span> test_y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># --------------------------- 此处上方加入读入模型和预测相关代码 -------------------------------</span>

    <span class="token comment"># 保证输出的是一个 numpy 数组</span>
    <span class="token keyword keyword-assert">assert</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>test_y<span class="token punctuation">)</span> <span class="token operator">==</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span>

    <span class="token comment"># 保证 test_y 的 shape 正确</span>
    <span class="token keyword keyword-assert">assert</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>n_test<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-return">return</span> test_y
</code></pre><h3 id="四-实验结果与分析">四、实验结果与分析 </h3>
<p>当采用epoch = 40 learning_rate = 0.001，batch_size = 16时，模型的预测效果如下：</p>
<div align="center">
<img src="image.png" width="80%">
</div>
可以看出，两项评估指标MAPE和MAE均较小，说明模型预测结果的精度和准确度较高，效果很好。
<p>由于在本次实验中，我们采用了唯一且确定的LSTM模型，所以影响预测精度的基本只有一些超参数的改变（例如batch_size，epoch，learning_rate等），所以下面将着重分析这些超参数的改变对预测精度的影响。<br>
<strong>batch_size:</strong><br>
取定learning_rate = 0.001, epoch = 50 后选取不同的batch_size，观察模型的预测效果，结果如下：</p>
<div align="center">
<img src="image-1.png" width="80%">
</div>
可以看出，预测的精度随着batch_size的增大而降低，这是因为batch_size越大，每次迭代时模型的参数更新越不频繁，导致模型的收敛速度变慢，从而影响了模型的预测精度，而且过大的batch_size会导致模型的泛化能力降低，在预测时的精度会下降。
<p><strong>epoch:</strong><br>
取定learning_rate = 0.001, batch_size = 32 后选取不同的epoch，观察模型的预测效果，结果如下：</p>
<div align="center">
<img src="image-2.png" width="80%">
</div>
可以看出，预测的精度随着epoch的增大而增大，这是因为epoch越大，模型的训练次数越多，模型的参数更新次数越多，模型越趋向于收敛，从而提高了模型的预测精度，但是训练的时间也会随之增长，而且，epoch过大可能会导致模型过拟合，从而影响模型的泛化能力。
<p><strong>learning_rate:</strong><br>
取定epoch = 50, batch_size = 32 后选取不同的learning_rate，观察模型的预测效果，结果如下：</p>
<div align="center">
<img src="image-3.png" width="80%">
</div>
当学习率过小时，loss的下降速度较低，模型的收敛速度过慢，预测精度较低，当学习率过大时，loss的下降速度过快，可能会导致模型的震荡，甚至无法收敛，预测精度较低。因此，调整选取合适的学习率是保证模型预测精度的关键。

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>